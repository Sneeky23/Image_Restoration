{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SuperResolution_AECNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "6HfBi5p1o9Dt"
      },
      "source": [
        "import os\n",
        "import zipfile \n",
        "import gdown\n",
        "import torch\n",
        "from natsort import natsorted\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import transforms\n",
        "\n",
        "## Setup\n",
        "## Number of gpus available\n",
        "ngpu = 1\n",
        "device = torch.device('cuda:0' if (\n",
        "    torch.cuda.is_available() and ngpu > 0) else 'cpu')\n",
        "\n",
        "## Fetch data from Google Drive \n",
        "# Root directory for the dataset\n",
        "data_root = 'data/celeba'\n",
        "# Path to folder with the dataset\n",
        "dataset_folder = f'{data_root}/img_align_celeba'\n",
        "# URL for the CelebA dataset\n",
        "url = 'https://drive.google.com/uc?id=1cNIac61PSA_LqDFYFUeyaQYekYPc75NH'\n",
        "#url = 'https://drive.google.com/file/d/0B7EVK8r0v71pZjFTYXZWM3FlRnM/view?usp=sharing&resourcekey=0-dYn9z10tMJOBAkviAcfdyQ'\n",
        "# Path to download the dataset to\n",
        "download_path = f'{data_root}/img_align_celeba.zip'\n",
        "\n",
        "# Create required directories \n",
        "if not os.path.exists(data_root):\n",
        "  os.makedirs(data_root)\n",
        "  os.makedirs(dataset_folder)\n",
        "\n",
        "# Download the dataset from google drive\n",
        "gdown.download(url, download_path, quiet=False)\n",
        "\n",
        "# Unzip the downloaded file \n",
        "with zipfile.ZipFile(download_path, 'r') as ziphandler:\n",
        "  ziphandler.extractall(dataset_folder)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filenames_list = []\n",
        "dataset_dir = f'{data_root}/img_align_celeba/img_align_celeba/'\n",
        "\n",
        "for filename in sorted(os.listdir(dataset_dir)):\n",
        "    filenames_list.append(dataset_dir + filename)\n",
        "\n",
        "filenames_list_train = filenames_list[:100000]\n",
        "filenames_list_test = filenames_list[100001:120000]\n",
        "\n",
        "print(len(filenames_list))"
      ],
      "metadata": {
        "id": "ccvaHo1Fvjje"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filenames_list_train[0]"
      ],
      "metadata": {
        "id": "GjBY5Vj7vmNJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Super Resolution class\n",
        "import numpy as np\n",
        "#from keras.utils import Sequence\n",
        "from tensorflow.keras.utils import Sequence\n",
        "\n",
        "from skimage import io, color\n",
        "from skimage.transform import resize\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "img_size = 128\n",
        "\n",
        "class Generator(Sequence):\n",
        "\n",
        "    def __init__(self, filenames_list, batch_size, img_size):\n",
        "        self.filenames_list = filenames_list\n",
        "        self.batch_size = batch_size\n",
        "        self.img_size = img_size\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.filenames_list) / float(self.batch_size)))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        batch_x = self.filenames_list[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
        "\n",
        "        input_tensor = np.empty((self.batch_size, int(self.img_size/2), int(self.img_size/2), 3), dtype=np.float32)\n",
        "        output_tensor = np.empty((self.batch_size, self.img_size, self.img_size, 3), dtype=np.float32)\n",
        "\n",
        "        i = 0\n",
        "        for filename in batch_x:\n",
        "\n",
        "            read_image = io.imread(filename)\n",
        "\n",
        "            image = resize(read_image, (self.img_size, self.img_size), anti_aliasing=False, mode='constant')\n",
        "            image_n = resize(read_image, (int(self.img_size/2), int(self.img_size/2)), anti_aliasing=False, mode='constant')\n",
        "\n",
        "            if image.shape == (self.img_size, self.img_size, 3) :\n",
        "                # array image for output tensor\n",
        "                output_tensor[i, :] = (image[:, :, :])\n",
        "                # array values for input tensor\n",
        "                input_tensor[i, :] = (image_n[:, :, :] ).reshape(int(self.img_size/2), int(self.img_size/2), 3)\n",
        "                i += 1\n",
        "\n",
        "                # print(image)\n",
        "                # io.imshow(image_n)\n",
        "                # plt.show()\n",
        "                # io.imshow(image)\n",
        "                # plt.show()\n",
        "\n",
        "\n",
        "        return input_tensor, output_tensor\n"
      ],
      "metadata": {
        "id": "Z48bj19Mvsf-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras\n",
        "from keras.models import Sequential, load_model, Model\n",
        "from keras.layers import Conv2D, Conv2DTranspose, BatchNormalization, Activation, Input, ZeroPadding2D, Concatenate, AveragePooling2D, UpSampling2D\n",
        "\n",
        "from time import time\n",
        "from tensorflow.python.keras.callbacks import TensorBoard\n",
        "#from keras.utils import plot_model\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "1iW7To0rwPky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "WpqZSInGwe6I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Root directory for the logs\n",
        "log_root = f'{data_root}/logs'\n",
        "# Path to folder with the dataset\n",
        "weights_root = f'{data_root}//weights'\n",
        "\n",
        "# Create required directories \n",
        "if not os.path.exists(log_root):\n",
        "  os.makedirs(log_root)\n",
        "  os.makedirs(weights_root)"
      ],
      "metadata": {
        "id": "vUSndI9lwrrh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_size = 64\n",
        "batch_size = 64\n",
        "\n",
        "\n",
        "training_batch_generator = Generator(filenames_list=filenames_list_train, batch_size=batch_size, img_size=img_size*2)\n",
        "testing_batch_generator = Generator(filenames_list=filenames_list_test, batch_size=batch_size, img_size=img_size*2)\n",
        "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(time()))\n"
      ],
      "metadata": {
        "id": "zbAU3lMOxr2m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model\n",
        "input_layer = Input(shape=(img_size, img_size, 3))\n",
        "\n",
        "hidden_layer_1 = Conv2D(32, (7, 7), activation='relu', padding='same')(input_layer)\n",
        "hidden_layer_1 = BatchNormalization()(hidden_layer_1)\n",
        "hidden_layer_1 = AveragePooling2D()(hidden_layer_1)\n",
        "hidden_layer_2 = Conv2D(64, (5, 5), activation='relu',  padding='same')(hidden_layer_1)\n",
        "hidden_layer_2 = BatchNormalization()(hidden_layer_2)\n",
        "hidden_layer_2 = AveragePooling2D()(hidden_layer_2)\n",
        "hidden_layer_2 = UpSampling2D()(hidden_layer_2)\n",
        "hidden_layer_3 = Conv2D(256, (3, 3), activation='relu', padding='same')(hidden_layer_2)\n",
        "hidden_layer_3 = BatchNormalization()(hidden_layer_3)\n",
        "hidden_layer_3 = UpSampling2D()(hidden_layer_3)\n",
        "hidden_layer_4 = Conv2D(64, (3, 3), activation='relu', padding='same')(hidden_layer_3)\n",
        "hidden_layer_4 = BatchNormalization()(hidden_layer_4)\n",
        "hidden_layer_4 = UpSampling2D()(hidden_layer_4)\n",
        "hidden_layer_5 = Conv2D(32, (3, 3), activation='relu', padding='same')(hidden_layer_4)\n",
        "hidden_layer_5 = BatchNormalization()(hidden_layer_5)\n",
        "\n",
        "output_layer = Conv2D(3, (3, 3), activation='tanh', padding='same')(hidden_layer_5)\n",
        "\n",
        "model = Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "opt = tensorflow.keras.optimizers.RMSprop()\n",
        "\n",
        "model.compile(optimizer=opt, loss='mse', metrics=['accuracy'])\n",
        "\n",
        "#plot_model(model, to_file='logs/cnn/cnn_model.png')\n",
        "print(model.summary())"
      ],
      "metadata": {
        "id": "-EvG5xDDyTJf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with tf.device(\"/gpu:0\"):\n",
        "   history = model.fit(training_batch_generator, epochs=10, verbose=1,workers=8,validation_data=testing_batch_generator)\n",
        "\n",
        "   print(history.history.keys())\n",
        "   #summarize history for accuracy\n",
        "   plt.plot(history.history['accuracy'])\n",
        "   #plt.plot(history.history['val_accuracy'])\n",
        "   plt.title('model accuracy')\n",
        "   plt.ylabel('accuracy')\n",
        "   plt.xlabel('epoch')\n",
        "   plt.legend(['train'], loc='upper left')\n",
        "   plt.savefig(log_root+\"/accuracy_plot.png\")\n",
        "   plt.show()\n",
        "   # summarize history for loss\n",
        "   plt.plot(history.history['loss'])\n",
        "   #plt.plot(history.history['val_loss'])\n",
        "   plt.title('model loss')\n",
        "   plt.ylabel('loss')\n",
        "   plt.xlabel('epoch')\n",
        "   plt.legend(['train'], loc='upper left')\n",
        "   plt.savefig(log_root+\"/loss_plot.png\")\n",
        "   plt.show()\n",
        "  #summarize history for accuracy test and train\n",
        "   plt.plot(history.history['accuracy'])\n",
        "   plt.plot(history.history['val_accuracy'])\n",
        "   plt.title('model accuracy')\n",
        "   plt.ylabel('accuracy')\n",
        "   plt.xlabel('epoch')\n",
        "   plt.legend(['train', 'test'], loc='upper left')\n",
        "   plt.savefig(log_root+\"/accuracy_val_plot.png\")\n",
        "   plt.show()\n",
        "   # summarize history for loss for test and train\n",
        "   plt.plot(history.history['loss'])\n",
        "   plt.plot(history.history['val_loss'])\n",
        "   plt.title('model loss')\n",
        "   plt.ylabel('loss')\n",
        "   plt.xlabel('epoch')\n",
        "   plt.legend(['train', 'test'], loc='upper left')\n",
        "   plt.savefig(log_root+\"/loss_val_plot.png\")\n",
        "   plt.show()\n",
        "\n",
        "model.save(weights_root+\"/AECNNs.h5\")"
      ],
      "metadata": {
        "id": "ifh8EDgXymeC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "from keras.models import load_model\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage import io, color , util\n",
        "from skimage.transform import resize\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "2H2sqEzyTxxV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_size = 128\n",
        "dataset_dir = f'{data_root}/img_align_celeba/img_align_celeba/'\n",
        "\n",
        "def ret_input_output_tensor(dataset_dir, n_images):\n",
        "    input_tensor = np.empty((n_images, int(img_size/2), int(img_size/2), 3))\n",
        "    output_tensor = np.empty((n_images, img_size, img_size, 3))\n",
        "\n",
        "    i = 0\n",
        "    print(len(os.listdir(dataset_dir)))\n",
        "    for filename in reversed(sorted(os.listdir(dataset_dir))):\n",
        "\n",
        "        if filename.endswith('.jpg'):\n",
        "\n",
        "            read_image = io.imread(dataset_dir + filename)\n",
        "            image = resize(read_image, (img_size, img_size, 3), anti_aliasing=False, mode='constant')\n",
        "            image_n = resize(read_image, (int(img_size/2), int(img_size/2)), anti_aliasing=False, mode='constant')\n",
        "\n",
        "\n",
        "            if image.shape == (img_size, img_size, 3):\n",
        "                # array image for output tensor\n",
        "                output_tensor[i, :] = (image[:, :, :])\n",
        "                # array values for input tensor\n",
        "                input_tensor[i, :] = (image_n[:, :, :]).reshape(int(img_size/2), int(img_size/2), 3)\n",
        "                i += 1\n",
        "\n",
        "        if i >= n_images: break\n",
        "\n",
        "    return input_tensor, output_tensor"
      ],
      "metadata": {
        "id": "LZQcn3CGTa04"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(os.listdir())\n",
        "model = load_model(\"/content/data/AECNNs.h5\")\n",
        "\n",
        "# prediction\n",
        "\n",
        "input_tensor, output_tensor = ret_input_output_tensor(dataset_dir, 10)\n",
        "prediction = model.predict(input_tensor)"
      ],
      "metadata": {
        "id": "gREC4WhsULv5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(10):\n",
        "    print(\"input tensor :\\n\", input_tensor[i].shape)\n",
        "    print(\"prediction :\\n\", prediction[i].shape)\n",
        "    print(\"output tensor :\\n\", output_tensor[i].shape)\n",
        "\n",
        "    input_image = input_tensor[i]\n",
        "    print(input_image.shape)\n",
        "    plt.imshow(input_image)\n",
        "    plt.show()\n",
        "    plt.imsave('/content/data/celeba/logs/'+str(i)+'_input.png', input_image)\n",
        "\n",
        "    output_image = prediction[i]\n",
        "    print(output_image.shape)\n",
        "\n",
        "    plt.imshow(output_image)\n",
        "    plt.show()\n",
        "    #plt.savefig('/content/data/celeba/logs/' + str(i) + '_prediction.png')\n",
        "    #plt.imsave('/content/data/celeba/logs/' + str(i) + '_prediction.png', output_image)\n",
        "\n",
        "\n",
        "\n",
        "    output_image = output_tensor[i]\n",
        "    plt.imshow(output_image)\n",
        "    plt.show()\n",
        "    plt.imsave('/content/data/celeba/logs/' + str(i) + '_actual.png', output_image)"
      ],
      "metadata": {
        "id": "Wvnigf3zUaPX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/data/logs.zip /content/data/celeba/logs"
      ],
      "metadata": {
        "id": "L5RmLLGWh7pE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}